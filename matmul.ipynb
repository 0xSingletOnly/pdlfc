{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is a re-implementation of Fast AI's lesson 10 notebook.\n",
    "\n",
    "The goal is to implement some basic matrix multiplication operations.\n",
    "\n",
    "We are allowed to use the following libraries:\n",
    "- Python and the included standard library\n",
    "- matplotlib\n",
    "- Jupyter notebooks and nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "This section is copied from the existing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_URL = 'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 33312\n",
      "-rw-r--r--  1 pj  staff  17051982 May 24 19:17 mnist.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -l data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = x_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the 1D list to a 2D matrix\n",
    "1. Using `yield`\n",
    "2. Using `iter`/`islice`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `yield`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(input_list, row_length):\n",
    "  for i in range(0, len(input_list), row_length): yield input_list[i: i+row_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0_yield_2d = list(chunks(img0, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img0_yield_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img0_yield_2d[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `iter`/`islice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(img0)\n",
    "row_length = 28\n",
    "\n",
    "img0_islice_2d = [list(islice(iterator, row_length)) for _ in range(len(img0) // row_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img0_islice_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img0_islice_2d[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare `yield` and `islice`'s speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53 µs ± 824 ns per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 list(chunks(img0, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38 µs ± 539 ns per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 [list(islice(iterator, row_length)) for _ in range(len(img0) // row_length)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find it interesting that `chunks` works slightly faster, but its standard deviation is much larger than that of `islice`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix:\n",
    "    def __init__(self, matrix):\n",
    "        self.matrix = matrix\n",
    "\n",
    "    def __getitem__(self, idxs):\n",
    "        return self.matrix[idxs[0]][idxs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0_mat = Matrix(img0_islice_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_mat[2,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(img0_islice_2d[2][15])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! Now we have implemented basic matrix operations in Python, we can use Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = x_train[:5]; m1.shape\n",
    "m2 = torch.randn(784, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive nested loop for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    (m1r, m1c), (m2r, m2c) = m1.shape, m2.shape\n",
    "    res = torch.zeros(m1r, m2c)\n",
    "    for i in range(m1r):\n",
    "        for j in range(m1c):\n",
    "            for k in range(m2c):\n",
    "                res[i, k] += m1[i, j] * m2[j, k]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.4936,  -5.6175, -22.5178,  -3.9274, -12.2499,   3.0905,  -7.8525,\n",
       "          -0.4918,  -1.8969, -15.1004],\n",
       "        [ -0.5469,   2.9690, -17.8994,  -6.0521, -27.5086,   9.8671,  -9.4390,\n",
       "          -1.5734,  -8.8437,  -7.7993],\n",
       "        [ -4.8420,   7.3685,  -7.9591, -11.0315,   6.6914, -10.7308,  12.4244,\n",
       "           8.7850,   8.4482,  -2.8377],\n",
       "        [ -4.1739,   1.5831, -10.6296,  -1.7576,  -1.8362,  12.7535,  -9.5721,\n",
       "          14.2302,  -5.5941, -10.1399],\n",
       "        [ -1.0859, -12.7273,  -0.1452,  -6.9904,  -9.4698,  19.9961,   3.7399,\n",
       "          -2.0317,  -2.5721,  -9.6477]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 ms ± 7.67 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit matmul(m1, m2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba for dot product function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "@jit(nopython=True)\n",
    "def dot(a, b):\n",
    "    summation = 0\n",
    "    for i in range(a.shape[0]):\n",
    "        summation += a[i] * b[i]\n",
    "\n",
    "    return summation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    (m1r, m1c), (m2r, m2c) = m1.shape, m2.shape\n",
    "    res = torch.zeros(m1r, m2c)\n",
    "    for i in range(m1r):\n",
    "        for j in range(m2c):\n",
    "                a, b = m1[i,:], m2[:, j]\n",
    "                res[i, j] = dot(a, b)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# convert m2 from torch tensor to numpy as numba needs np\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m m2 \u001b[39m=\u001b[39m m2\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "# convert m2 from torch tensor to numpy as numba needs np\n",
    "m2 = m2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.4936,  -5.6175, -22.5178,  -3.9274, -12.2499,   3.0905,  -7.8525,\n",
       "          -0.4918,  -1.8969, -15.1004],\n",
       "        [ -0.5469,   2.9690, -17.8994,  -6.0521, -27.5086,   9.8671,  -9.4390,\n",
       "          -1.5734,  -8.8437,  -7.7993],\n",
       "        [ -4.8420,   7.3685,  -7.9591, -11.0315,   6.6914, -10.7308,  12.4244,\n",
       "           8.7850,   8.4482,  -2.8377],\n",
       "        [ -4.1739,   1.5831, -10.6296,  -1.7576,  -1.8362,  12.7535,  -9.5721,\n",
       "          14.2302,  -5.5941, -10.1399],\n",
       "        [ -1.0859, -12.7273,  -0.1452,  -6.9904,  -9.4698,  19.9961,   3.7399,\n",
       "          -2.0317,  -2.5721,  -9.6477]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 µs ± 1.38 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit matmul(m1, m2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    (m1r, m1c), (m2r, m2c) = m1.shape, m2.shape\n",
    "    res = torch.zeros(m1r, m2c)\n",
    "    for i in range(m1r):\n",
    "        for j in range(m2c):\n",
    "                a, b = m1[i,:], m2[:, j]\n",
    "                res[i, j] = torch.sum(a * b)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.4936,  -5.6175, -22.5178,  -3.9274, -12.2499,   3.0905,  -7.8525,\n",
       "          -0.4918,  -1.8969, -15.1004],\n",
       "        [ -0.5469,   2.9690, -17.8994,  -6.0521, -27.5086,   9.8671,  -9.4390,\n",
       "          -1.5734,  -8.8437,  -7.7993],\n",
       "        [ -4.8420,   7.3685,  -7.9591, -11.0315,   6.6914, -10.7308,  12.4244,\n",
       "           8.7850,   8.4482,  -2.8377],\n",
       "        [ -4.1739,   1.5831, -10.6296,  -1.7576,  -1.8362,  12.7535,  -9.5721,\n",
       "          14.2302,  -5.5941, -10.1399],\n",
       "        [ -1.0859, -12.7273,  -0.1452,  -6.9904,  -9.4698,  19.9961,   3.7399,\n",
       "          -2.0317,  -2.5721,  -9.6477]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.from_numpy(m1)\n",
    "m2 = torch.from_numpy(m2)\n",
    "\n",
    "matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479 µs ± 2.79 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit matmul(m1, m2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "The examples below illustrate how we can use broadcasting to help with our matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "\n",
    "c = tensor([10.,20,30]); c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put `None` at an axis that does not exist to add a dimension at that axis. Works the same way as unsqueeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that an extra dimension has indeed been added. We went from a vector to a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:, None].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to add an extra dimension at the second dimension (column), we convert our vector of 3 elements to 3 rows of 1 element each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100., 200., 300.],\n",
       "        [200., 400., 600.],\n",
       "        [300., 600., 900.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None, :] * c[:, None]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 matrices of 1 by 3 and 3 by 1. In order to accomodate the element wise multiplication, our first element `c[None, :]` of 1 by 3 has its first dimension 'expanded' (in reality we use a stride of 0) to become a 3 by 3 matrix. In other words, the first dimension of 1 is expanded to 3 to match the second element which has 3 rows.\n",
    "\n",
    "A similar logic applies for `c[:, None]`, where it has its second dimension expanded from 1 to 3 in order to match the second dimension of `c[None, :]`.\n",
    "\n",
    "Thus, we end up with 2 matrices with dimensions 3 by 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None] > c[:,None]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar logic applies for boolean operation too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.,  9.],\n",
       "        [16., 25., 36.],\n",
       "        [49., 64., 81.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m*m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "When operating on two arrays/tensors, Numpy/PyTorch compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when\n",
    "- they are equal, or\n",
    "- one of them is 1, in which case that dimension is broadcasted to make it the same size\n",
    "\n",
    "Arrays do not need to have the same number of dimensions. For example, if you have a 256*256*3 array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\n",
    "\n",
    "Image  (3d array): 256 x 256 x 3\n",
    "Scale  (1d array):             3\n",
    "Result (3d array): 256 x 256 x 3\n",
    "\n",
    "The numpy documentation includes several examples of what dimensions can and can not be broadcast together.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matmul with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    (m1r, m1c), (m2r, m2c) = m1.shape, m2.shape\n",
    "    res = torch.zeros(m1r, m2c)\n",
    "    for i in range(m1r):\n",
    "      digit = m1[i]\n",
    "      res[i] = (digit[:,None] * m2).sum(axis=0)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.4936,  -5.6175, -22.5178,  -3.9274, -12.2499,   3.0905,  -7.8525,\n",
       "          -0.4918,  -1.8969, -15.1004],\n",
       "        [ -0.5469,   2.9690, -17.8994,  -6.0521, -27.5086,   9.8671,  -9.4390,\n",
       "          -1.5734,  -8.8437,  -7.7993],\n",
       "        [ -4.8420,   7.3685,  -7.9591, -11.0315,   6.6914, -10.7308,  12.4244,\n",
       "           8.7850,   8.4482,  -2.8377],\n",
       "        [ -4.1739,   1.5831, -10.6296,  -1.7576,  -1.8362,  12.7535,  -9.5721,\n",
       "          14.2302,  -5.5941, -10.1399],\n",
       "        [ -1.0859, -12.7273,  -0.1452,  -6.9904,  -9.4698,  19.9961,   3.7399,\n",
       "          -2.0317,  -2.5721,  -9.6477]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.6 µs ± 142 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit matmul(m1, m2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have obtained a speed-up of 7000x!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
