{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini batch training\n",
    "In this notebook, we are first going to implement cross entropy, then move on to mini-batch training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor,nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input, input_dim = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(input_dim, nh, c)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy loss\n",
    "We implement the log of cross entropy loss (for easier computation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(pred), dim=1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting will now be automatically applied to divide `pred` with the sum of the exponent of each `x_j`, where `x_j` is the value for each of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to use the LogSumExp trick. The rationale is that we want the gradients to be as precise as possible (suppose we have a region where we would otherwise 'bounce around'). However, the exponent of a value may be very large, which makes the computed value less precise (because of how a computer can lose precision when the magnitude gets very large)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.10, 0.14, 0.21,  ..., 0.14, 0.11, 0.14], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pred.max(-1)[0]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp_softmax(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return (m + (x - m[:, None]).exp().sum(-1).log()).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsumexp_softmax(pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.28],\n",
       "        [2.30],\n",
       "        [2.29],\n",
       "        ...,\n",
       "        [2.30],\n",
       "        [2.28],\n",
       "        [2.30]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsumexp_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.79],\n",
       "        [ 9.97],\n",
       "        [ 9.91],\n",
       "        ...,\n",
       "        [10.01],\n",
       "        [ 9.80],\n",
       "        [ 9.94]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.exp().sum(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - logsumexp_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, our logsumexp trick is working correctly! Meanwhile, Pytorch actually already implements this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated the softmax, we can proceed to calculate the cross entropy loss for some target $x$ and some prediction $p(x)$ by $- \\sum x \\log p(x) $.\n",
    "\n",
    "However, given that our y values are 'one hot encoded' (in reality they represent an index of the predicted class), we can simplify the above equation to $ - \\log(p_i)$, where $p_i$ is the probability of the actual class.\n",
    "\n",
    "The above is also known as negative log likelihood loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 8, 4, 8])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000]), torch.Size([50000]))"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[torch.arange(sm_pred.shape[0]), y_train].shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.30, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[torch.arange(sm_pred.shape[0]), y_train].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(sm_pred, tgt):\n",
    "    return -1. * sm_pred[torch.arange(sm_pred.shape[0]), tgt].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(sm_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pytorch, softmax and negative log likelihood loss are combined together in the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "loss(pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop\n",
    "A basic training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 50\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06], grad_fn=<SelectBackward0>),\n",
       " torch.Size([50, 10]))"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 9., 3., 8., 5., 9., 3., 9., 3., 9., 5., 3., 9., 9., 3., 9., 9., 5., 8., 7., 9., 5., 3., 8., 9., 5., 9., 5., 5., 9., 3., 5., 9.,\n",
       "        7., 5., 7., 9., 9., 3., 9., 3., 5., 3., 8., 3., 5., 9., 5., 9., 5.])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = preds.argmax(dim=1).float()\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "        3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, actual): \n",
    "    return 1. * sum(preds.argmax(dim=1) == actual) / actual.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.08)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.5\n",
    "epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.30, 0.08\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "y_pred = model(xb)\n",
    "report(loss_function(y_pred, yb), y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.12, 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08, 0.96\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    for b in range(0, num_input, bs):\n",
    "        s = slice(b, min(b+bs, num_input))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "\n",
    "    report(loss, y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we are getting pretty good accuracy on our training set in just 3 epochs! Recall that we actually have 10 classes, so an accuracy of 96% on a balanced dataset is actually very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "We can now use nn's parameters to help us reduce the number of lines of code. nn's parameters refer to the weights and biases of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, nh, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, nh)\n",
    "        self.l2 = nn.Linear(nh, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim, nh, c.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.04,  0.03, -0.02,  ...,  0.03,  0.03,  0.00],\n",
       "         [ 0.04,  0.01,  0.03,  ..., -0.01,  0.02,  0.03],\n",
       "         [ 0.03,  0.03, -0.01,  ...,  0.01, -0.01,  0.00],\n",
       "         ...,\n",
       "         [-0.01, -0.02, -0.03,  ..., -0.01,  0.00, -0.00],\n",
       "         [-0.01, -0.02,  0.00,  ...,  0.00,  0.01, -0.01],\n",
       "         [ 0.03,  0.02, -0.02,  ..., -0.01, -0.01, -0.04]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.01, -0.01, -0.00,  0.01, -0.03,  0.02, -0.03,  0.01, -0.01, -0.00,  0.03, -0.02, -0.01, -0.02,  0.00,  0.03, -0.04,  0.01, -0.00,\n",
       "         -0.02, -0.01, -0.02,  0.03,  0.02, -0.01,  0.02, -0.02, -0.02, -0.00, -0.02, -0.01, -0.01,  0.02,  0.01,  0.03,  0.03,  0.02, -0.02,\n",
       "          0.02, -0.00,  0.01, -0.03,  0.03,  0.01,  0.03, -0.01,  0.02, -0.01,  0.03,  0.00], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[    -0.05,      0.02,      0.07,      0.09,      0.10,      0.12,     -0.13,      0.10,     -0.09,     -0.08,     -0.12,     -0.01,\n",
       "               0.07,     -0.00,      0.12,     -0.03,     -0.07,     -0.14,      0.10,      0.13,     -0.12,      0.14,      0.12,      0.08,\n",
       "              -0.11,      0.03,     -0.09,      0.12,      0.01,     -0.03,      0.06,     -0.00,      0.01,     -0.05,      0.11,      0.14,\n",
       "               0.07,      0.05,     -0.09,     -0.03,     -0.01,     -0.01,      0.08,      0.02,     -0.09,     -0.05,      0.03,      0.13,\n",
       "              -0.08,      0.13],\n",
       "         [     0.09,     -0.04,      0.00,      0.14,     -0.13,     -0.06,      0.03,     -0.09,     -0.11,      0.05,      0.04,     -0.02,\n",
       "              -0.04,     -0.03,      0.01,     -0.10,     -0.03,     -0.02,      0.00,      0.07,      0.10,     -0.08,     -0.14,     -0.02,\n",
       "              -0.13,     -0.08,      0.07,      0.04,     -0.13,     -0.13,     -0.05,      0.12,     -0.08,      0.13,      0.13,     -0.10,\n",
       "               0.06,      0.08,     -0.13,     -0.08,     -0.06,     -0.11,      0.07,      0.06,      0.09,      0.04,     -0.13,      0.04,\n",
       "              -0.10,     -0.01],\n",
       "         [    -0.12,      0.07,     -0.05,     -0.06,     -0.13,      0.06,     -0.12,      0.03,     -0.11,      0.00,     -0.05,     -0.11,\n",
       "              -0.01,      0.14,      0.11,      0.00,      0.02,     -0.08,     -0.03,      0.00,      0.06,      0.09,     -0.02,      0.02,\n",
       "              -0.07,      0.03,      0.05,      0.05,      0.06,      0.05,      0.09,      0.08,      0.00,     -0.01,     -0.04,     -0.02,\n",
       "               0.06,      0.14,      0.01,      0.05,     -0.00,      0.09,     -0.12,     -0.10,      0.04,     -0.06,     -0.12,      0.10,\n",
       "              -0.14,     -0.09],\n",
       "         [     0.14,     -0.09,      0.03,     -0.00,     -0.03,      0.10,      0.09,     -0.14,     -0.05,      0.04,     -0.04,      0.02,\n",
       "              -0.08,      0.09,     -0.04,      0.12,      0.13,      0.10,     -0.10,      0.13,     -0.06,     -0.00,      0.11,     -0.05,\n",
       "               0.12,     -0.01,     -0.13,      0.02,     -0.09,     -0.12,     -0.11,     -0.08,      0.13,      0.02,     -0.01,      0.02,\n",
       "               0.14,      0.12,     -0.11,     -0.06,      0.13,      0.04,      0.05,      0.10,      0.14,     -0.10,     -0.01,     -0.08,\n",
       "               0.01,     -0.13],\n",
       "         [     0.11,      0.11,      0.13,      0.08,     -0.03,      0.13,      0.02,      0.04,     -0.08,      0.13,     -0.12,     -0.02,\n",
       "              -0.11,      0.10,      0.04,     -0.04,     -0.02,     -0.10,     -0.03,      0.02,      0.12,      0.07,      0.04,      0.02,\n",
       "              -0.07,     -0.02,     -0.06,     -0.11,     -0.12,     -0.12,     -0.13,     -0.04,     -0.11,      0.13,     -0.12,     -0.11,\n",
       "               0.01,      0.10,      0.05,      0.07,     -0.00,     -0.02,     -0.05,      0.03,      0.04,      0.04,      0.01,      0.00,\n",
       "               0.03,     -0.10],\n",
       "         [    -0.00,      0.04,      0.09,      0.04,     -0.13,      0.06,      0.00,     -0.02,     -0.13,      0.05,     -0.05,      0.00,\n",
       "               0.03,      0.02,     -0.08,      0.09,      0.14,      0.02,      0.10,     -0.10,      0.09,      0.07,      0.11,      0.08,\n",
       "               0.11,     -0.14,     -0.00,     -0.07,      0.12,     -0.13,     -0.00,      0.10,      0.12,      0.07,      0.14,      0.06,\n",
       "              -0.12,     -0.03,      0.06,      0.13,     -0.06,     -0.11,      0.04,     -0.04,      0.11,      0.06,     -0.09,      0.04,\n",
       "              -0.11,     -0.11],\n",
       "         [    -0.05,     -0.09,     -0.08,     -0.09,      0.06,     -0.07,      0.06,     -0.03,      0.06,     -0.13,     -0.07,      0.14,\n",
       "              -0.03,      0.12,      0.00,      0.06,     -0.02,     -0.01,      0.02,     -0.01,     -0.03,     -0.12,     -0.12,      0.00,\n",
       "              -0.09,     -0.03,     -0.09,     -0.06,     -0.07,      0.10,     -0.04,      0.00,      0.03,     -0.02,     -0.12,     -0.07,\n",
       "               0.05,      0.12,     -0.04,      0.10,     -0.08,      0.12,     -0.11,      0.11,      0.14,      0.01,     -0.01,      0.02,\n",
       "              -0.08,     -0.04],\n",
       "         [     0.02,     -0.05,      0.05,     -0.04,     -0.02,      0.11,      0.06,      0.08,     -0.07,      0.07,      0.02,     -0.00,\n",
       "               0.05,      0.09,     -0.08,     -0.06,      0.08,      0.01,      0.07,      0.13,      0.12,      0.07,     -0.00,     -0.01,\n",
       "              -0.05,      0.02,     -0.05,      0.01,     -0.14,     -0.02,      0.05,      0.10,     -0.12,      0.06,     -0.06,     -0.10,\n",
       "               0.06,     -0.02,      0.10,     -0.12,     -0.13,      0.11,      0.13,     -0.10,      0.11,     -0.06,      0.07,     -0.01,\n",
       "               0.03,      0.08],\n",
       "         [     0.03,     -0.01,     -0.08,      0.08,      0.03,      0.12,     -0.08,     -0.12,      0.13,      0.07,     -0.04,      0.07,\n",
       "              -0.01,      0.02,      0.04,     -0.10,      0.10,     -0.11,      0.12,     -0.09,     -0.13,     -0.09,     -0.01,      0.06,\n",
       "              -0.05,     -0.00,     -0.05,      0.04,      0.06,      0.03,      0.05,      0.02,     -0.04,      0.11,     -0.12,     -0.06,\n",
       "               0.04,     -0.08,      0.10,      0.01,      0.01,      0.10,      0.05,     -0.09,      0.05,      0.07,      0.07,     -0.11,\n",
       "               0.08,     -0.02],\n",
       "         [    -0.02,     -0.12,     -0.14,     -0.05,     -0.07,     -0.03,      0.07,     -0.06,      0.09,      0.00,     -0.00,      0.03,\n",
       "               0.05,      0.07,     -0.10,      0.04,     -0.13,     -0.09,     -0.02,     -0.04,      0.03,      0.04,      0.11,      0.10,\n",
       "              -0.06,      0.13,      0.09,      0.06,      0.11,     -0.00,     -0.04,     -0.02,      0.02,     -0.12,      0.02,      0.09,\n",
       "              -0.09,      0.02,     -0.07,     -0.12,      0.01,     -0.03,      0.06,     -0.13,      0.12,      0.04,      0.02,     -0.13,\n",
       "              -0.00,     -0.00]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.01, -0.06,  0.03, -0.08, -0.12,  0.02, -0.03,  0.09, -0.05,  0.04], requires_grad=True)]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that calling `parameters()` on an object inheriting `nn.Module` gives us access to the list of weights and biases in that model.\n",
    "\n",
    "We can now shorten our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13, 0.96\n",
      "0.08, 0.98\n",
      "0.09, 0.98\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    for b in range(0, x_train.shape[0], bs):\n",
    "        s = slice(b, min(x_train.shape[0], b+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p -= p.grad * lr\n",
    "            model.zero_grad()\n",
    "\n",
    "    report(loss, y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our code is now shorter. Next, we can use PyTorch's `optim` to make the code even shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optim\n",
    "PyTorch's `optim` offers various optimisation algorithms for training neural network, such as SGD, Adam etc. We will implement our own SGD optimizer from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDOptimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x17a72c740>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(input_dim, nh), nn.ReLU(), nn.Linear(nh, c))\n",
    "optim = SGDOptimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further shorten our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.98\n",
      "0.12, 0.96\n",
      "0.12, 0.98\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    for b in range(0, num_input, bs):\n",
    "        s = slice(b, min(num_input, b+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "            \n",
    "    report(loss, y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have implemented SGD Optimizer from scratch, we can use PyTorch's `optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(input_dim,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader\n",
    "It is clunky to retrieve `xb`, `yb` separately in our code. We want to retrieve them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert(len(train_ds) == len(x_train))\n",
    "assert(len(valid_ds) == len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5, 28*28)\n",
    "assert yb.shape == (5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shorten our traning loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16, 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10, 0.98\n",
      "0.10, 0.96\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    for b in range(0, num_input, bs):\n",
    "        s = slice(b, min(num_input, b+bs))\n",
    "        xb, yb = train_ds[s]\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "            \n",
    "    report(loss, y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current training loop iterates over elements in the dataset as:\n",
    "`for b in range(0, num_input, bs):\n",
    "  s = slice(b, min(num_input, b+bs))\n",
    "  xb, yb = train_ds[s]`\n",
    "\n",
    "Let's replace this with a Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, dataset, bs):\n",
    "        self.dataset = dataset\n",
    "        self.bs = bs\n",
    "\n",
    "    # defines how an object of this class behaves in an iteration context\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.dataset), self.bs): yield self.dataset[i: i+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, bs)\n",
    "valid_dl = Dataloader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.13, 0.96\n",
      "0.11, 0.96\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "            \n",
    "    report(loss, y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now implemented a Dataloader from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling\n",
    "We want our Dataloader to sample randomly during training (to smoothen out any potential bias in how the data is prepared), and sample non-randomly during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False):\n",
    "        self.n, self.shuffle = len(ds), shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "it = iter(ss)\n",
    "for i in range(5): print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38864\n",
      "6875\n",
      "17031\n",
      "11550\n",
      "23101\n"
     ]
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "it = iter(ss)\n",
    "for i in range(5): print(next(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are shuffling our dataset. Let's use the shuffled values as indices to select the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        module\n",
      "\u001b[0;31mString form:\u001b[0m <module 'fastcore.all' from '/Users/pj/miniconda3/envs/np/lib/python3.11/site-packages/fastcore/all.py'>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/np/lib/python3.11/site-packages/fastcore/all.py\n",
      "\u001b[0;31mSource:\u001b[0m     \n",
      "\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfoundation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "??fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from fc.chunked(iter(self.sampler), self.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = BatchSampler(ss, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "val_samp = BatchSampler(Sampler(valid_ds), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, batchs=train_samp)\n",
    "val_dl = Dataloader(valid_ds, batchs=val_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training rows in this epoch: 50000\n",
      "0.05, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training rows in this epoch: 50000\n",
      "0.04, 0.98\n",
      "Num training rows in this epoch: 50000\n",
      "0.09, 0.92\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    num_train_rows = 0\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        num_train_rows += xb.shape[0]\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "            \n",
    "    print(\"Num training rows in this epoch:\", num_train_rows)\n",
    "    report(loss, y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3,6,8,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3, 6, 8, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `__getitem__()` is the same as indexing into the tensor directly.\n",
    "\n",
    "To translate this to multiple workers, we can use `map` to call `__getitem__()` on the corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3,6], [8,1])): print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, ds, batchs, num_workers=1, collate_fn=collate):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.num_workers) as ex:\n",
    "            print(\"started worker\")\n",
    "            yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, batchs=train_samp, num_workers=2)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pj/Documents/code/pdlfc/04_minibatch_training.ipynb Cell 106\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pj/Documents/code/pdlfc/04_minibatch_training.ipynb#Y231sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xb, yb \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(it)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pj/Documents/code/pdlfc/04_minibatch_training.ipynb#Y231sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m xb\u001b[39m.\u001b[39mshape, yb\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;32m/Users/pj/Documents/code/pdlfc/04_minibatch_training.ipynb Cell 106\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pj/Documents/code/pdlfc/04_minibatch_training.ipynb#Y231sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m mp\u001b[39m.\u001b[39mPool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers) \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pj/Documents/code/pdlfc/04_minibatch_training.ipynb#Y231sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mstarted worker\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pj/Documents/code/pdlfc/04_minibatch_training.ipynb#Y231sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39myield from\u001b[39;00m ex\u001b[39m.\u001b[39;49mmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mds\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m, \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatchs))\n",
      "File \u001b[0;32m~/miniconda3/envs/np/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/np/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/np/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/np/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/np/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xb, yb = next(it)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason each worker is facing problem with executing the mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch DataLoader\n",
    "We can now use PyTorch's DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds), bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "val_dl = DataLoader(valid_ds, batch_sampler=val_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27, 0.94\n",
      "0.03, 1.00\n",
      "0.08, 0.96\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "for i in range(epochs):\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "            \n",
    "    report(loss, y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch can actually automatically generate the `BatchSampler` and `RandomSampler` for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
    "val_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10, 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07, 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08, 0.98\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "for i in range(epochs):\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "            \n",
    "    report(loss, y_pred, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "We check our model's performance on a validation set at the end of each epoch. We need to call `model.train()` before training, and `model.eval()` before inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.14612301837652922 0.9564999985694885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.13874237489886582 0.9602999991178512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.10953246485907585 0.968100000321865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    val_acc = 0\n",
    "    count = 0\n",
    "    for batch in val_dl:\n",
    "        xb, yb = batch\n",
    "        n = len(xb)\n",
    "        y_pred = model(xb)\n",
    "        loss = loss_function(y_pred, yb)\n",
    "        val_loss += loss.item() * n\n",
    "        val_acc += accuracy(y_pred, yb).item() * n\n",
    "        count += n\n",
    "\n",
    "    print(i, val_loss/count, val_acc/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully implemented PyTorch's DataLoaders from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "np",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
